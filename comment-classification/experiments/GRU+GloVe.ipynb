{
  "cells": [
    {
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "9827a445-3be5-4d91-a5a6-5120a4923534",
        "collapsed": true,
        "_uuid": "0d8e2c016a5382c839c9999dc6e09608ebcec2a6",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Basic Config\n\nembed_size = 50 # how big is each word vector\nmax_features = 20000 # how many unique words to use (i.e num rows in embedding vector)\nmaxlen = 100 # max number of words in a comment to use",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "collapsed": true,
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": false
      },
      "cell_type": "code",
      "source": "train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n\nlist_sentences_train = train[\"comment_text\"].fillna(\"_na_\").values\nlist_sentences_test = test[\"comment_text\"].fillna(\"_na_\").values\nlist_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\ny = train[list_classes].values\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "6bf8c0db-e895-4778-90e3-83ee82b6eed4",
        "_uuid": "f7c8822b2d3fffd79ecb1d437cffc9ee3b3fbead",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "from keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\n\ntokenizer = Tokenizer(num_words=max_features)\ntokenizer.fit_on_texts(list(list_sentences_train))\n\nlist_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\nlist_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)\n\nX_t = pad_sequences(list_tokenized_train, maxlen=maxlen)\nX_te = pad_sequences(list_tokenized_test, maxlen=maxlen)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "e4f699dd-33e9-491c-bd0b-47059af1828a",
        "_uuid": "90e03fa3d4665dec3f8bf99d6afcf09040786d82",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "EMBEDDING_FILE = '../input/glove.6B.50d.txt'\ndef get_coefs(word,*arr): \n    return word, np.asarray(arr, dtype='float32')\nembeddings_index = dict(get_coefs(*o.strip().split()) for o in open(EMBEDDING_FILE))\n\nall_embs = np.stack(embeddings_index.values())\nemb_mean,emb_std = all_embs.mean(), all_embs.std()\nemb_mean,emb_std",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "e04ce97e-2627-45c6-896f-5ddc84d18598",
        "collapsed": true,
        "_uuid": "d17d1069ffe8dbdfd25149f01212bdd20e77194e",
        "trusted": false
      },
      "cell_type": "code",
      "source": "word_index = tokenizer.word_index\nnb_words = min(max_features, len(word_index))\nembedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\nfor word, i in word_index.items():\n    if i >= max_features: continue\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None: embedding_matrix[i] = embedding_vector",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "546d2938-c722-426d-89ef-1f87df99b3a7",
        "_uuid": "bb23951df6ba1fc8edbef4ba4bfdbbd1b1b33f82",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "embedding",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "e73f7540-04f4-46fa-8291-3721b7a221e3",
        "collapsed": true,
        "_uuid": "59aebfc89c636b48a1ed5ee77e39c933f32c2ce7",
        "trusted": false
      },
      "cell_type": "code",
      "source": "from keras.layers import Dense, Input, GRU, Embedding, Dropout, Activation\nfrom keras.layers import Bidirectional, GlobalMaxPool1D\nfrom keras.models import Model\nfrom keras import initializers, regularizers, constraints, optimizers, layers\n\ninp = Input(shape=(maxlen,))\nx = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\nx = Bidirectional(GRU(50, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))(x)\nx = GlobalMaxPool1D()(x)\nx = Dense(50, activation=\"relu\")(x)\nx = Dropout(0.1)(x)\nx = Dense(6, activation=\"sigmoid\")(x)\nmodel = Model(inputs=inp, outputs=x)\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "ceaa6593-1510-4a43-972d-7c2ee648b658",
        "collapsed": true,
        "_uuid": "a8fae22c525518b09792a101a2832c7be920ea01",
        "trusted": false
      },
      "cell_type": "code",
      "source": "model.fit(X_t, y, batch_size=32, epochs=2, validation_split=0.1);",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "342c4457-fa36-46ec-856a-e5073b6ea9c0",
        "collapsed": true,
        "_uuid": "49fad26ced627e9ccb33ab9b58fbea03daeef3e3",
        "trusted": false
      },
      "cell_type": "code",
      "source": "print (X_t)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "7b61d603-2c97-40f5-875f-6f6e942abfd9",
        "collapsed": true,
        "_uuid": "ea7983029a9bb75f4236d624c9442793412f818d",
        "trusted": false
      },
      "cell_type": "code",
      "source": "y_test = model.predict([X_te], batch_size=1024, verbose=1)\n\nprint (y_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "822f4660-df33-4068-b3d1-90bdef226b18",
        "collapsed": true,
        "_uuid": "1bbab949706ce0025fc36bbea6bf964d98a4496c",
        "trusted": false
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "7d1957bf-3fdc-4a69-8c30-1f33f6dfb864",
        "collapsed": true,
        "_uuid": "28faf44b184c23d29efb8c334ed35bcf25478708",
        "trusted": false
      },
      "cell_type": "code",
      "source": "sample_submission = pd.read_csv('../input/sample_submission.csv')\nprint (len(test))\nprint (len(y_test))\nsubmit = {}\nfor i in range(len(test)):\n    submit[test['id'][i]] = y_test[i]\nprint (submit)\nsubmit = pd.DataFrame(submit, columns=[\"id\",\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"])\nprint (submit)\n\n# sample_submission[list_classes] = y_test\n# sample_submission.to_csv('submission_gru.csv', index=False)",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}
